{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5py\n",
    "from datetime import datetime, timedelta\n",
    "import sys\n",
    "\n",
    "from matplotlib.colors import TwoSlopeNorm, LogNorm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import geopandas as gpd\n",
    "\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.patches import Rectangle\n",
    "import textwrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MO', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'array_summary', 'cos_sim', 'datetime', 'get_diagonal', 'get_diagonal_prob', 'get_mondays', 'get_travelling_out', 'h5py', 'h5py_to_4d_array', 'np', 'pd', 'region_mobility', 'region_out_desitination', 'relativedelta', 'relave_diff_D', 'test', 'timedelta']\n"
     ]
    }
   ],
   "source": [
    "folder_path = \"../\"\n",
    "sys.path.append(folder_path)\n",
    "sys.path.append(\"../mobility_function/\")\n",
    "from mobility_function import analysis as ma\n",
    "from importlib import reload\n",
    "import mobility_function.analysis as ma\n",
    "import mobility_function.hurricane_plotting as mhp\n",
    "ma = reload(ma)\n",
    "mhp = reload(mhp)\n",
    "print(dir(ma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of matrix: (7, 17, 3144, 3144)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "Ms_h_base = ma.h5py_to_4d_array(f'../data/mobility/M_raw_20240909.h5')\n",
    "Ms_h0 = ma.h5py_to_4d_array(f'../data/mobility/M_raw_20240916.h5')\n",
    "Ms_h = ma.h5py_to_4d_array(f'../data/mobility/M_raw_20240923.h5')\n",
    "Ms_h1 = ma.h5py_to_4d_array(f'../data/mobility/M_raw_20240930.h5')\n",
    "print('size of matrix:', Ms_h_base.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_H = np.concatenate([Ms_h_base, Ms_h0, Ms_h, Ms_h1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of selected counties 270\n",
      "no of destination county 230\n"
     ]
    }
   ],
   "source": [
    "### read back the selected counties based on the storm track\n",
    "cutoff_mile = 50\n",
    "hurricane = \"helene\"\n",
    "with open(\"../results/{}/counties_geoid_cut_{}.txt\".format(hurricane, cutoff_mile), \"r\") as f:\n",
    "    county_list = [line.strip() for line in f]\n",
    "county_list = [int(x) for x in county_list]\n",
    "geo_idx = pd.read_csv('geoid_idx_names.csv')\n",
    "selected_idx = geo_idx[geo_idx['GEOID'].isin(county_list)].county_idx.values\n",
    "print('no of selected counties',len(selected_idx))\n",
    "selected_names = geo_idx[geo_idx['GEOID'].isin(county_list)].NAME.values\n",
    "### destination index\n",
    "with open(\"../results/{}/dest_counties_geoid_{}.txt\".format(hurricane, cutoff_mile), \"r\") as f:\n",
    "    dst_county_list = [line.strip() for line in f]\n",
    "dst_county_list = [int(x) for x in dst_county_list]\n",
    "print('no of destination county',len(dst_county_list))\n",
    "dst_idx = geo_idx[geo_idx['GEOID'].isin(dst_county_list)].county_idx.values\n",
    "dst_names = geo_idx[geo_idx['GEOID'].isin(dst_county_list)].NAME.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_regout_base = ma.region_out_desitination(Ms_h_base, selected_idx)\n",
    "M_regout_0 = ma.region_out_desitination(Ms_h0,selected_idx)\n",
    "M_regout = ma.region_out_desitination(Ms_h,selected_idx)\n",
    "M_regout_1 = ma.region_out_desitination(Ms_h1,selected_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_regout_all = np.concatenate([M_regout_base,M_regout_0,M_regout,M_regout_1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file('../data/county_geo/tl_2023_us_county/tl_2023_us_county.shp')\n",
    "gdf['GEOID'] = gdf['GEOID'].astype(int)\n",
    "projected_crs = \"EPSG:5070\"  # USA Contiguous Albers Equal Area\n",
    "geo_centers = gdf.to_crs(projected_crs)\n",
    "### using the original crs 4326 for distance calculation as the hawaii and alaska are included\n",
    "#### sort the df to match with the order of selected counties\n",
    "geo_centers = geo_centers.merge(geo_idx, on=['GEOID', 'NAME'])\n",
    "geo_centers.sort_values(by='county_idx', inplace=True)\n",
    "\n",
    "set_rg = geo_centers[geo_centers['GEOID'].isin(county_list)]  \n",
    "set_dst = geo_centers[geo_centers['GEOID'].isin(dst_county_list)]  # Next 310 elements\n",
    "centroids_rg = set_rg.geometry.centroid\n",
    "centroids_dst = set_dst.geometry.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.distance import geodesic\n",
    "\n",
    "# Convert centroids to WGS84 (EPSG:4326)\n",
    "centroids_rg_4326 = centroids_rg.to_crs(\"EPSG:4326\")\n",
    "centroids_dst_4326 = centroids_dst.to_crs(\"EPSG:4326\")\n",
    "# Initialize the distance array\n",
    "distance_array_km = np.zeros((len(centroids_rg), len(centroids_dst)))\n",
    "# Calculate distances between all pairs of centroids\n",
    "for i, center_rg in enumerate(centroids_rg_4326):\n",
    "    for j, center_dst in enumerate(centroids_dst_4326):\n",
    "        coords_rg = (center_rg.y, center_rg.x)  # (latitude, longitude)\n",
    "        coords_dst = (center_dst.y, center_dst.x)  # (latitude, longitude)\n",
    "        distance_array_km[i, j] = geodesic(coords_rg, coords_dst).kilometers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### sort properly!!!\n",
    "# df_distance = pd.DataFrame(data=distance_array_km, index=selected_names, columns=dst_names)\n",
    "# df_distance.to_csv('df_distance_helene.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_counties(distance_array_km, threshold):\n",
    "    check_matrix = distance_array_km<=threshold\n",
    "    within_count = 0\n",
    "    for des in range(len(dst_county_list)):\n",
    "        within = np.sum(check_matrix[:,des]) >= 1\n",
    "        if within:\n",
    "            within_count += 1\n",
    "    print('no of counties within {} km:'.format(threshold), within_count, within_count/len(dst_county_list))\n",
    "    return within_count, within_count/len(dst_county_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of counties within 400 km: 131 0.5695652173913044\n"
     ]
    }
   ],
   "source": [
    "_ , _ = count_counties(distance_array_km, 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def travel_dis_per_visit(M_region_dst, distance_array_km):\n",
    "    no_selected_counties = M_region_dst.shape[0]\n",
    "    no_dst_counties = M_region_dst.shape[1]\n",
    "    travel_distance_ls = []\n",
    "    for i in range(no_selected_counties):\n",
    "        for j in range(no_dst_counties):\n",
    "            dst_km_ij = distance_array_km[i, j]\n",
    "            v_ij = int(round(M_region_dst[i, j])) ## round half to even\n",
    "            travel_distance_ls.extend([dst_km_ij]*v_ij)\n",
    "    weighted_avg = np.sum(distance_array_km*M_region_dst)/np.sum(M_region_dst)\n",
    "    return travel_distance_ls, weighted_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 270, 3144)\n"
     ]
    }
   ],
   "source": [
    "print(M_regout.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 hurricane week 420.2874714149899\n",
      "base week 399.93267271801733\n"
     ]
    }
   ],
   "source": [
    "M_region_out_hwk_sum = np.sum(M_regout,axis=0)\n",
    "M_region_dst_hwk_sum = M_region_out_hwk_sum[:,dst_idx]\n",
    "travel_distance_h_ls, w_dis_h = travel_dis_per_visit(M_region_dst_hwk_sum, distance_array_km)\n",
    "print(cutoff_mile,'hurricane week', w_dis_h)\n",
    "M_region_out_basewk_sum = np.sum(M_regout_base,axis=0)\n",
    "M_region_dst_basewk_sum = M_region_out_basewk_sum[:,dst_idx]\n",
    "travel_distance_base_ls, w_dis_base = travel_dis_per_visit(M_region_dst_basewk_sum, distance_array_km)\n",
    "print('base week', w_dis_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(426003017.9951086)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(M_region_out_hwk_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(60533899)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.array(travel_distance_h_ls)<=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.209734777206451"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(60533899/426003017.9951086)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_m_rg_dst_sum = M_region_dst_hwk_sum - M_region_dst_basewk_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_change = [] \n",
    "neg_change = []\n",
    "for i in range(len(selected_idx)):\n",
    "    for j in range(len(dst_idx)):\n",
    "        diff_ij = diff_m_rg_dst_sum[i,j]            \n",
    "        if diff_ij > 0:\n",
    "            pos_change.extend([distance_array_km[i,j]]*int(round(diff_ij)))\n",
    "        else:\n",
    "            neg_change.extend([distance_array_km[i,j]]*-int(round(diff_ij))\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.concatenate([np.linspace(0, 4500, 46), [float('inf')]])\n",
    "\n",
    "counts_pos, bin_edges_pos = np.histogram(pos_change, bins=bins)\n",
    "counts_neg, bin_edges_neg = np.histogram(neg_change, bins=bins)\n",
    "\n",
    "wd_p = np.diff(bin_edges_pos)\n",
    "wd_p[-1] = wd_p[0]\n",
    "wd_n = np.diff(bin_edges_neg)\n",
    "wd_n[-1] = wd_n[0]\n",
    "\n",
    "pos_bin_centers = (bin_edges_pos[:-1] + bin_edges_pos[1:]) / 2\n",
    "pos_bin_centers[-1] = bin_edges_pos[-2] + wd_p[0]\n",
    "\n",
    "neg_bin_centers = (bin_edges_neg[:-1] + bin_edges_neg[1:]) / 2\n",
    "neg_bin_centers[-1] = bin_edges_neg[-2] + wd_n[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('bins_{}_{}.txt'.format(hurricane,cutoff_mile), np.array([wd_n, neg_bin_centers, counts_neg, pos_bin_centers, counts_pos]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
